{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.updates import nesterov_momentum, adagrad\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from scipy.special import expit\n",
    "import random\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.random_projection import SparseRandomProjection, GaussianRandomProjection\n",
    "from sklearn.manifold import LocallyLinearEmbedding, MDS\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.kernel_approximation import RBFSampler, Nystroem\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "random.seed(21)\n",
    "np.random.seed(21)\n",
    "\n",
    "train_file = 'C:\\\\Users\\\\jacob\\Dropbox\\\\Documents\\\\Python\\\\numerai\\\\numerai_training_data.csv'\n",
    "test_file =  'C:\\\\Users\\\\jacob\\Dropbox\\\\Documents\\\\Python\\\\numerai\\\\numerai_tournament_data.csv'\n",
    "output_file = 'C:\\\\Users\\\\jacob\\Dropbox\\\\Documents\\\\Python\\\\numerai\\\\predictions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets try to write some modular functions\n",
    "def load_train_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.drop( 'validation', axis = 1 , inplace = True )\n",
    "    df[\"c1\"] = pd.Categorical.from_array(df.c1).codes    \n",
    "    X = df.values.copy()\n",
    "    np.random.shuffle(X)\n",
    "    X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(labels).astype(np.int32)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(np.log(1+X))\n",
    "    rbm1 = SVC(probability=True, verbose=1).fit(X, y)\n",
    "    rbm2 = RandomForestClassifier(n_estimators=300, criterion='entropy', max_features='auto', bootstrap=False, oob_score=False, n_jobs=-1, verbose=1).fit(X, y)\n",
    "    rbm3 = xgb.XGBClassifier(n_estimators=50,max_depth=11,verbose=1).fit(X, y)\n",
    "    X =  np.append(X, np.power(rbm1.predict_proba()*rbm2.predict_proba(X)*rbm3.predict_proba(X), (1/3.0))   , 1)\n",
    "    return X, y, encoder, scaler, rbm1, rbm2, rbm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_data(path, scaler, rbm1, rbm2, rbm3):\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"c1\"] = pd.Categorical.from_array(df.c1).codes    \n",
    "    X = df.values.copy()\n",
    "    X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
    "    X = scaler.transform(np.log(1+X))\n",
    "    X =  np.append(X, np.power(rbm1.predict_proba(X)*rbm2.predict_proba(X)*rbm3.predict_proba(X), (1/3.0)), 1)\n",
    "    return X, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(p, ids, encoder, name=output_file):\n",
    "    d = {'probability':p[:,1],'t_id':ids}\n",
    "    df= pd.DataFrame(data=d)\n",
    "    df.to_csv(name, columns = ( 't_id', 'probability' ), index = None )\n",
    "    print(\"Wrote submission to file {}.\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Data\n",
    "X, y, encoder, scaler, rbm1, rbm2, rbm3 = load_train_data(train_file)\n",
    "X_test, ids = load_test_data(test_file, scaler, rbm1, rbm2, rbm3)\n",
    "\n",
    "num_classes = len(encoder.classes_)\n",
    "num_features = X.shape[1]\n",
    "\n",
    "print(num_classes); print(num_features); print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NN parameters\n",
    "layers0 = [('input', InputLayer),\n",
    "('dropoutf', DropoutLayer),\n",
    "('dense0', DenseLayer),\n",
    "('dropout', DropoutLayer),\n",
    "('dense1', DenseLayer),\n",
    "('dropout2', DropoutLayer),\n",
    "('dense2', DenseLayer),\n",
    "('output', DenseLayer)]\n",
    "\n",
    "\n",
    "net0 = NeuralNet(layers=layers0,\n",
    "\n",
    "input_shape=(None, num_features),\n",
    "dropoutf_p=0.1,\n",
    "dense0_num_units=600,\n",
    "dropout_p=0.3,\n",
    "dense1_num_units=600,\n",
    "dropout2_p=0.1,\n",
    "dense2_num_units=600,\n",
    "\n",
    "output_num_units=num_classes,\n",
    "output_nonlinearity=softmax,\n",
    "\n",
    "#update=nesterov_momentum,\n",
    "update=adagrad,\n",
    "update_learning_rate=0.008,\n",
    "eval_size=0.2,\n",
    "verbose=1,\n",
    "max_epochs=20)\n",
    "\n",
    "\n",
    "net0.fit(X, y)\n",
    "p = net0.predict_proba(X_test)\n",
    "num_runs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now loop and loop and loop!\n",
    "for jj in xrange(num_runs):\n",
    "  print(jj)\n",
    "  X, y, encoder, scaler, rbm1, rbm2, rbm3 = load_train_data(train_file)\n",
    "  X_test, ids = load_test_data(test_file, scaler, rbm1, rbm2, rbm3)\n",
    "  num_classes = len(encoder.classes_)\n",
    "  num_features = X.shape[1]\n",
    "  net0.fit(X, y)\n",
    "  p = p + net0.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = p/(num_runs+1.0)\n",
    "make_submission(p, ids, encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
